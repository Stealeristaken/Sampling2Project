# Sampling2Project
This repo contains a class project for  Survey Sampling II at 2024 Spring Semester. 



> **Abstract**

This study investigates the effects of various sampling techniques, with
a particular focus on

top-k sampling, on the performance and sustainability of language
models. By fine-tuning

models on both sampled and non-sampled datasets, we compare metrics such
as training

time, loss, GPU power consumption, and overall efficiency. Our findings
reveal that top-k

sampling significantly enhances model performance and reduces
computational costs,

demonstrating its potential for sustainable AI development. The results
suggest that

employing effective sampling methods can lead to more efficient and
environmentally

friendly training processes for language models.

> *Key* *Words*: language models, sampling techniques, top-k sampling,
> sustainability, performance, GPU power consumption

